{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Breast Cancer Diagnosis Based on Cell Nuclei Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carolyn Nohejl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnohejl/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import Image\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.datasets import make_classification;\n",
    "from sklearn import preprocessing, neighbors, model_selection\n",
    "\n",
    "from sklearn import tree, ensemble, metrics, model_selection, externals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('breast_cancer_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.replace([\"M\", \"B\"],[\"1\",\"0\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change classifier to a numeric.  This is required to use some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diagnosis'] = pd.to_numeric(df['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'concave points_mean': 'concave_points_mean', 'concave points_se': 'concave_points_se', 'concave points_worst': 'concave_points_worst'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null int64\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave_points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave_points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave_points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "dtypes: float64(30), int64(2)\n",
      "memory usage: 142.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test sets (70/30)Â¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same random state as I did for the EDA portion, to result in the same test and train dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    249\n",
       "1    149\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    108\n",
       "1     63\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Random Forest - All 30 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature matrix X with all features except diagnosis and ID, and response vector y including diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df_train[df_train.columns.values]\n",
    "X.drop(['id','diagnosis'], axis = 1, inplace = True)\n",
    "\n",
    "y = df_train.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training set 60% and test set 40% of the overall training set (df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(X,y, train_size = .6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators = 1000,\n",
    "        min_samples_leaf = 5,\n",
    "        oob_score = True,\n",
    "        random_state = 0).\\\n",
    "    fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOB score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94537815126050417"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 fold cross validation score on training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94545454545454555"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(model, train_X, train_y, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16715931454388719, 'concave_points_worst'),\n",
       " (0.13366127363499894, 'concave_points_mean'),\n",
       " (0.1174542576640398, 'perimeter_worst'),\n",
       " (0.099679487882633755, 'radius_worst'),\n",
       " (0.093355900316311788, 'area_worst'),\n",
       " (0.081154916673909866, 'concavity_mean'),\n",
       " (0.054142055938401851, 'concavity_worst'),\n",
       " (0.049025239156765835, 'perimeter_mean'),\n",
       " (0.035210498515225508, 'radius_mean'),\n",
       " (0.032636132921040235, 'area_mean'),\n",
       " (0.022275230670363317, 'area_se'),\n",
       " (0.018244777522621172, 'compactness_worst'),\n",
       " (0.011895227652925895, 'compactness_mean'),\n",
       " (0.01176052704479969, 'radius_se'),\n",
       " (0.011495530457791623, 'texture_worst'),\n",
       " (0.011005383867656664, 'symmetry_worst'),\n",
       " (0.0074339374683463234, 'perimeter_se'),\n",
       " (0.0072703222121763503, 'smoothness_worst'),\n",
       " (0.0062425646185192123, 'texture_mean'),\n",
       " (0.0059140307436010477, 'fractal_dimension_worst'),\n",
       " (0.0040081706736959022, 'concavity_se'),\n",
       " (0.0028348740774689174, 'concave_points_se'),\n",
       " (0.0025285891563906118, 'smoothness_mean'),\n",
       " (0.0024003392763913998, 'compactness_se'),\n",
       " (0.0022897662010329203, 'fractal_dimension_mean'),\n",
       " (0.0022015678487127014, 'smoothness_se'),\n",
       " (0.0020233603969543861, 'symmetry_mean'),\n",
       " (0.0018211660219076098, 'fractal_dimension_se'),\n",
       " (0.0015716804964940427, 'symmetry_se'),\n",
       " (0.0013038763449350079, 'texture_se')]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model.feature_importances_, \\\n",
    "           X.columns.values), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hypothesized that I could make the best model using 3 variables representing shape, size and potentially texture.  From this list, I would pick concave points worst, perimeter worst, and area worst (rather than incuding concave points mean, as it would be a second concave points variable).  I would rule out texture as all three texture values are lower in the list.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm model on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_final = df[df.columns.values]\n",
    "X_final.drop(['id','diagnosis'], axis = 1, inplace = True)\n",
    "\n",
    "y_final = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X_final, test_X_final, train_y_final, test_y_final = model_selection.train_test_split(X_final,y_final, train_size = .6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_rf_final = tree.DecisionTreeClassifier(max_depth=None, min_samples_leaf=5, random_state=0).fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_rf_final = ensemble.RandomForestClassifier(n_estimators = 1000,\n",
    "#         min_samples_leaf = 5,\n",
    "#         oob_score = True,\n",
    "#         random_state = 0).\\\n",
    "#     fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 fold CV score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94133944486885679"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_selection.cross_val_score(model_rf_final, train_X_final, train_y_final, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94133944486885679"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(model, train_X_final, train_y_final, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94460526315789473"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_selection.cross_val_score(model_rf_final, X, y, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94460526315789473"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.cross_val_score(model, X, y, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "94% accuracy across the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16715931454388719, 'concave_points_worst'),\n",
       " (0.13366127363499894, 'concave_points_mean'),\n",
       " (0.1174542576640398, 'perimeter_worst'),\n",
       " (0.099679487882633755, 'radius_worst'),\n",
       " (0.093355900316311788, 'area_worst'),\n",
       " (0.081154916673909866, 'concavity_mean'),\n",
       " (0.054142055938401851, 'concavity_worst'),\n",
       " (0.049025239156765835, 'perimeter_mean'),\n",
       " (0.035210498515225508, 'radius_mean'),\n",
       " (0.032636132921040235, 'area_mean'),\n",
       " (0.022275230670363317, 'area_se'),\n",
       " (0.018244777522621172, 'compactness_worst'),\n",
       " (0.011895227652925895, 'compactness_mean'),\n",
       " (0.01176052704479969, 'radius_se'),\n",
       " (0.011495530457791623, 'texture_worst'),\n",
       " (0.011005383867656664, 'symmetry_worst'),\n",
       " (0.0074339374683463234, 'perimeter_se'),\n",
       " (0.0072703222121763503, 'smoothness_worst'),\n",
       " (0.0062425646185192123, 'texture_mean'),\n",
       " (0.0059140307436010477, 'fractal_dimension_worst'),\n",
       " (0.0040081706736959022, 'concavity_se'),\n",
       " (0.0028348740774689174, 'concave_points_se'),\n",
       " (0.0025285891563906118, 'smoothness_mean'),\n",
       " (0.0024003392763913998, 'compactness_se'),\n",
       " (0.0022897662010329203, 'fractal_dimension_mean'),\n",
       " (0.0022015678487127014, 'smoothness_se'),\n",
       " (0.0020233603969543861, 'symmetry_mean'),\n",
       " (0.0018211660219076098, 'fractal_dimension_se'),\n",
       " (0.0015716804964940427, 'symmetry_se'),\n",
       " (0.0013038763449350079, 'texture_se')]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(model_rf_final.feature_importances_, \\\n",
    "           X_final.columns.values), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't understand why the top feature weighting is so different when the entire dataset is used rather than the training set.  I will leverage the top features from the training set for KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Backward Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will perform a logistic regression using the top variables (contributing at least 5%) from my random forest model as a starting point and systematically remove variables. I will first leverage statsmodels, then scikit learn for the 10 fold correlation once I have my final features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.121928\n",
      "         Iterations 11\n"
     ]
    }
   ],
   "source": [
    "train_X_LR = df_train[['concave_points_worst','concave_points_mean','perimeter_worst','radius_worst','area_worst','concavity_mean','concavity_worst']]\n",
    "train_X_LR = sm.add_constant(train_X_LR)\n",
    "train_c_LR = df_train['diagnosis']\n",
    "logit=sm.Logit(train_c_LR, train_X_LR)\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diagnosis</td>    <th>  No. Observations:  </th>  <td>   398</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   390</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Sep 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.8156</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:45:01</td>     <th>  Log-Likelihood:    </th> <td> -48.527</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -263.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.238e-88</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    0.2288</td> <td>    8.209</td> <td>    0.028</td> <td> 0.978</td> <td>  -15.860    16.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_worst</th> <td>   11.0359</td> <td>   19.546</td> <td>    0.565</td> <td> 0.572</td> <td>  -27.273    49.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_mean</th>  <td>   99.6932</td> <td>   41.421</td> <td>    2.407</td> <td> 0.016</td> <td>   18.510   180.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perimeter_worst</th>      <td>   -0.1910</td> <td>    0.099</td> <td>   -1.929</td> <td> 0.054</td> <td>   -0.385     0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>radius_worst</th>         <td>   -0.5396</td> <td>    1.292</td> <td>   -0.418</td> <td> 0.676</td> <td>   -3.072     1.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>area_worst</th>           <td>    0.0258</td> <td>    0.011</td> <td>    2.262</td> <td> 0.024</td> <td>    0.003     0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concavity_mean</th>       <td>  -34.3794</td> <td>   14.984</td> <td>   -2.294</td> <td> 0.022</td> <td>  -63.747    -5.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concavity_worst</th>      <td>   14.5735</td> <td>    5.516</td> <td>    2.642</td> <td> 0.008</td> <td>    3.762    25.384</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              diagnosis   No. Observations:                  398\n",
       "Model:                          Logit   Df Residuals:                      390\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Sat, 16 Sep 2017   Pseudo R-squ.:                  0.8156\n",
       "Time:                        12:45:01   Log-Likelihood:                -48.527\n",
       "converged:                       True   LL-Null:                       -263.17\n",
       "                                        LLR p-value:                 1.238e-88\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    0.2288      8.209      0.028      0.978       -15.860    16.317\n",
       "concave_points_worst    11.0359     19.546      0.565      0.572       -27.273    49.345\n",
       "concave_points_mean     99.6932     41.421      2.407      0.016        18.510   180.877\n",
       "perimeter_worst         -0.1910      0.099     -1.929      0.054        -0.385     0.003\n",
       "radius_worst            -0.5396      1.292     -0.418      0.676        -3.072     1.993\n",
       "area_worst               0.0258      0.011      2.262      0.024         0.003     0.048\n",
       "concavity_mean         -34.3794     14.984     -2.294      0.022       -63.747    -5.012\n",
       "concavity_worst         14.5735      5.516      2.642      0.008         3.762    25.384\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove radius_worst and re-run logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.122144\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "train_X_LR = df_train[['concave_points_worst','concave_points_mean','perimeter_worst','area_worst','concavity_mean','concavity_worst']]\n",
    "train_X_LR = sm.add_constant(train_X_LR)\n",
    "train_c_LR = df_train['diagnosis']\n",
    "logit=sm.Logit(train_c_LR, train_X_LR)\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diagnosis</td>    <th>  No. Observations:  </th>  <td>   398</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Sep 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.8153</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:45:44</td>     <th>  Log-Likelihood:    </th> <td> -48.613</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -263.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.526e-89</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   -2.7960</td> <td>    4.013</td> <td>   -0.697</td> <td> 0.486</td> <td>  -10.660     5.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_worst</th> <td>    8.8676</td> <td>   18.905</td> <td>    0.469</td> <td> 0.639</td> <td>  -28.185    45.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_mean</th>  <td>  100.0847</td> <td>   41.686</td> <td>    2.401</td> <td> 0.016</td> <td>   18.382   181.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perimeter_worst</th>      <td>   -0.2131</td> <td>    0.084</td> <td>   -2.539</td> <td> 0.011</td> <td>   -0.378    -0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>area_worst</th>           <td>    0.0218</td> <td>    0.006</td> <td>    3.693</td> <td> 0.000</td> <td>    0.010     0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concavity_mean</th>       <td>  -34.1054</td> <td>   14.934</td> <td>   -2.284</td> <td> 0.022</td> <td>  -63.375    -4.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concavity_worst</th>      <td>   15.1249</td> <td>    5.394</td> <td>    2.804</td> <td> 0.005</td> <td>    4.554    25.696</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              diagnosis   No. Observations:                  398\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Sat, 16 Sep 2017   Pseudo R-squ.:                  0.8153\n",
       "Time:                        12:45:44   Log-Likelihood:                -48.613\n",
       "converged:                       True   LL-Null:                       -263.17\n",
       "                                        LLR p-value:                 1.526e-89\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   -2.7960      4.013     -0.697      0.486       -10.660     5.068\n",
       "concave_points_worst     8.8676     18.905      0.469      0.639       -28.185    45.920\n",
       "concave_points_mean    100.0847     41.686      2.401      0.016        18.382   181.787\n",
       "perimeter_worst         -0.2131      0.084     -2.539      0.011        -0.378    -0.049\n",
       "area_worst               0.0218      0.006      3.693      0.000         0.010     0.033\n",
       "concavity_mean         -34.1054     14.934     -2.284      0.022       -63.375    -4.836\n",
       "concavity_worst         15.1249      5.394      2.804      0.005         4.554    25.696\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove concave_points_worst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.122421\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "train_X_LR = df_train[['concave_points_mean','perimeter_worst','area_worst','concavity_mean','concavity_worst']]\n",
    "train_X_LR = sm.add_constant(train_X_LR)\n",
    "train_c_LR = df_train['diagnosis']\n",
    "logit=sm.Logit(train_c_LR, train_X_LR)\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diagnosis</td>    <th>  No. Observations:  </th>  <td>   398</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   392</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Sep 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.8149</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:46:18</td>     <th>  Log-Likelihood:    </th> <td> -48.724</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -263.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.745e-90</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>               <td>   -2.5486</td> <td>    3.930</td> <td>   -0.648</td> <td> 0.517</td> <td>  -10.251     5.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_mean</th> <td>  115.5608</td> <td>   26.044</td> <td>    4.437</td> <td> 0.000</td> <td>   64.516   166.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perimeter_worst</th>     <td>   -0.2142</td> <td>    0.084</td> <td>   -2.562</td> <td> 0.010</td> <td>   -0.378    -0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>area_worst</th>          <td>    0.0219</td> <td>    0.006</td> <td>    3.695</td> <td> 0.000</td> <td>    0.010     0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concavity_mean</th>      <td>  -38.2359</td> <td>   12.304</td> <td>   -3.108</td> <td> 0.002</td> <td>  -62.351   -14.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concavity_worst</th>     <td>   16.8824</td> <td>    3.911</td> <td>    4.317</td> <td> 0.000</td> <td>    9.218    24.547</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              diagnosis   No. Observations:                  398\n",
       "Model:                          Logit   Df Residuals:                      392\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Sat, 16 Sep 2017   Pseudo R-squ.:                  0.8149\n",
       "Time:                        12:46:18   Log-Likelihood:                -48.724\n",
       "converged:                       True   LL-Null:                       -263.17\n",
       "                                        LLR p-value:                 1.745e-90\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "---------------------------------------------------------------------------------------\n",
       "const                  -2.5486      3.930     -0.648      0.517       -10.251     5.154\n",
       "concave_points_mean   115.5608     26.044      4.437      0.000        64.516   166.606\n",
       "perimeter_worst        -0.2142      0.084     -2.562      0.010        -0.378    -0.050\n",
       "area_worst              0.0219      0.006      3.695      0.000         0.010     0.033\n",
       "concavity_mean        -38.2359     12.304     -3.108      0.002       -62.351   -14.121\n",
       "concavity_worst        16.8824      3.911      4.317      0.000         9.218    24.547\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All remaining variables are significant: concave_points_mean, perimeter_worst, area_worst, concavity_mean, concavity_worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.224390\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "train_X_LR2 = df_train[['concave_points_worst']]\n",
    "train_X_LR2 = sm.add_constant(train_X_LR2)\n",
    "train_c_LR2 = df_train['diagnosis']\n",
    "logit=sm.Logit(train_c_LR2, train_X_LR2)\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diagnosis</td>    <th>  No. Observations:  </th>  <td>   398</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   396</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Sep 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.6607</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:28:22</td>     <th>  Log-Likelihood:    </th> <td> -89.307</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -263.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.320e-77</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   -8.3471</td> <td>    0.859</td> <td>   -9.717</td> <td> 0.000</td> <td>  -10.031    -6.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_worst</th> <td>   63.4395</td> <td>    6.603</td> <td>    9.608</td> <td> 0.000</td> <td>   50.499    76.380</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              diagnosis   No. Observations:                  398\n",
       "Model:                          Logit   Df Residuals:                      396\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sat, 16 Sep 2017   Pseudo R-squ.:                  0.6607\n",
       "Time:                        13:28:22   Log-Likelihood:                -89.307\n",
       "converged:                       True   LL-Null:                       -263.17\n",
       "                                        LLR p-value:                 1.320e-77\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   -8.3471      0.859     -9.717      0.000       -10.031    -6.664\n",
       "concave_points_worst    63.4395      6.603      9.608      0.000        50.499    76.380\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added perimeter_worst, as the second most important feature in the random forest model (skipped concave points mean because I assumed it reflects a very similar feature to concave points worst):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.148541\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "train_X_LR2 = df_train[['concave_points_worst','perimeter_worst']]\n",
    "train_X_LR2 = sm.add_constant(train_X_LR2)\n",
    "train_c_LR2 = df_train['diagnosis']\n",
    "logit=sm.Logit(train_c_LR2, train_X_LR2)\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diagnosis</td>    <th>  No. Observations:  </th>  <td>   398</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   395</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Sep 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.7754</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:54:06</td>     <th>  Log-Likelihood:    </th> <td> -59.119</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -263.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.400e-89</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  -18.1385</td> <td>    2.430</td> <td>   -7.466</td> <td> 0.000</td> <td>  -22.900   -13.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_worst</th> <td>   41.2781</td> <td>    7.590</td> <td>    5.438</td> <td> 0.000</td> <td>   26.401    56.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perimeter_worst</th>      <td>    0.1160</td> <td>    0.020</td> <td>    5.693</td> <td> 0.000</td> <td>    0.076     0.156</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              diagnosis   No. Observations:                  398\n",
       "Model:                          Logit   Df Residuals:                      395\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sat, 16 Sep 2017   Pseudo R-squ.:                  0.7754\n",
       "Time:                        13:54:06   Log-Likelihood:                -59.119\n",
       "converged:                       True   LL-Null:                       -263.17\n",
       "                                        LLR p-value:                 2.400e-89\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  -18.1385      2.430     -7.466      0.000       -22.900   -13.377\n",
       "concave_points_worst    41.2781      7.590      5.438      0.000        26.401    56.155\n",
       "perimeter_worst          0.1160      0.020      5.693      0.000         0.076     0.156\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added radius worst, as the 3rd most important feature in the random forest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.140632\n",
      "         Iterations 9\n"
     ]
    }
   ],
   "source": [
    "train_X_LR2 = df_train[['concave_points_worst','perimeter_worst','radius_worst']]\n",
    "train_X_LR2 = sm.add_constant(train_X_LR2)\n",
    "train_c_LR2 = df_train['diagnosis']\n",
    "logit=sm.Logit(train_c_LR2, train_X_LR2)\n",
    "result=logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>diagnosis</td>    <th>  No. Observations:  </th>  <td>   398</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   394</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 16 Sep 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.7873</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>13:43:06</td>     <th>  Log-Likelihood:    </th> <td> -55.972</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -263.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.678e-89</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  -19.4234</td> <td>    2.655</td> <td>   -7.314</td> <td> 0.000</td> <td>  -24.628   -14.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>concave_points_worst</th> <td>   50.0697</td> <td>    8.979</td> <td>    5.576</td> <td> 0.000</td> <td>   32.471    67.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perimeter_worst</th>      <td>   -0.0703</td> <td>    0.079</td> <td>   -0.894</td> <td> 0.371</td> <td>   -0.224     0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>radius_worst</th>         <td>    1.2469</td> <td>    0.518</td> <td>    2.405</td> <td> 0.016</td> <td>    0.231     2.263</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              diagnosis   No. Observations:                  398\n",
       "Model:                          Logit   Df Residuals:                      394\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sat, 16 Sep 2017   Pseudo R-squ.:                  0.7873\n",
       "Time:                        13:43:06   Log-Likelihood:                -55.972\n",
       "converged:                       True   LL-Null:                       -263.17\n",
       "                                        LLR p-value:                 1.678e-89\n",
       "========================================================================================\n",
       "                           coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  -19.4234      2.655     -7.314      0.000       -24.628   -14.219\n",
       "concave_points_worst    50.0697      8.979      5.576      0.000        32.471    67.669\n",
       "perimeter_worst         -0.0703      0.079     -0.894      0.371        -0.224     0.084\n",
       "radius_worst             1.2469      0.518      2.405      0.016         0.231     2.263\n",
       "========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped here, given that perimeter worst is no longer statistically significant.  Will leverage scikit learn with concave points worst and perimeter worst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - SciKit Learn for 10 fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward selection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First apply SciKit Learn Logistic Regression to the training set, leveraging the features selected via statsmodels above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = df_train[df_train.columns.values]\n",
    "W.drop(['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se','area_se', 'smoothness_se', 'compactness_se', 'concavity_se','concave_points_se', 'symmetry_se', 'fractal_dimension_se','radius_worst', 'texture_worst','smoothness_worst', 'compactness_worst','concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst'], axis = 1, inplace = True)\n",
    "\n",
    "c = df_train.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.02881</td>\n",
       "      <td>0.01329</td>\n",
       "      <td>97.19</td>\n",
       "      <td>725.9</td>\n",
       "      <td>0.15640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.08092</td>\n",
       "      <td>0.02800</td>\n",
       "      <td>91.99</td>\n",
       "      <td>632.1</td>\n",
       "      <td>0.33080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.14500</td>\n",
       "      <td>0.06300</td>\n",
       "      <td>114.10</td>\n",
       "      <td>809.2</td>\n",
       "      <td>0.32190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.17640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.02974</td>\n",
       "      <td>0.02443</td>\n",
       "      <td>97.58</td>\n",
       "      <td>729.8</td>\n",
       "      <td>0.10490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.08606</td>\n",
       "      <td>0.02872</td>\n",
       "      <td>62.56</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.14340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>85.51</td>\n",
       "      <td>521.7</td>\n",
       "      <td>0.28730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.6</td>\n",
       "      <td>0.03866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.06463</td>\n",
       "      <td>113.90</td>\n",
       "      <td>869.3</td>\n",
       "      <td>0.40690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.11450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     concavity_mean  concave_points_mean  perimeter_worst  area_worst  \\\n",
       "149         0.02881              0.01329            97.19       725.9   \n",
       "124         0.08092              0.02800            91.99       632.1   \n",
       "421         0.14500              0.06300           114.10       809.2   \n",
       "195         0.03873              0.02377            90.81       600.6   \n",
       "545         0.02974              0.02443            97.58       729.8   \n",
       "..              ...                  ...              ...         ...   \n",
       "71          0.08606              0.02872            62.56       284.4   \n",
       "106         0.07070              0.03485            85.51       521.7   \n",
       "270         0.00725              0.00625            94.44       684.6   \n",
       "435         0.11260              0.06463           113.90       869.3   \n",
       "102         0.02383              0.01770            84.58       547.8   \n",
       "\n",
       "     concavity_worst  \n",
       "149          0.15640  \n",
       "124          0.33080  \n",
       "421          0.32190  \n",
       "195          0.17640  \n",
       "545          0.10490  \n",
       "..               ...  \n",
       "71           0.14340  \n",
       "106          0.28730  \n",
       "270          0.03866  \n",
       "435          0.40690  \n",
       "102          0.11450  \n",
       "\n",
       "[398 rows x 5 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accurately classified 88.75 percent of the testing data\n"
     ]
    }
   ],
   "source": [
    "W_train, W_test, c_train, c_test = train_test_split(W, c, \n",
    "                                                   test_size=0.4,\n",
    "                                                   random_state=42)\n",
    "#Step 2\n",
    "lr = LogisticRegression()\n",
    "lr.fit(W_train, c_train)\n",
    "\n",
    "#Step 3\n",
    "preds = lr.predict(W_test)\n",
    "\n",
    "#Step 4\n",
    "testing_score = accuracy_score(c_test, preds)\n",
    "\n",
    "print (\"The model accurately classified {:.2f} percent of the testing data\".format(testing_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model produces an accuracy score of 91.96 percent\n"
     ]
    }
   ],
   "source": [
    "#Intialize, fit, and score the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(W,c)\n",
    "\n",
    "score = lr.score(W,c)\n",
    "\n",
    "print (\"The model produces an accuracy score of {:.2f} percent\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy score is 91.41 percent\n"
     ]
    }
   ],
   "source": [
    "#Use cross_val_score method to generate the average accuracy score for 10 CVs\n",
    "mean_cv_score = cross_val_score(LogisticRegression(), W,c, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "print (\"The cross validated accuracy score is {:.2f} percent\").format(mean_cv_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation on the entire data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_final = df[df.columns.values]\n",
    "W_final.drop(['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se','area_se', 'smoothness_se', 'compactness_se', 'concavity_se','concave_points_se', 'symmetry_se', 'fractal_dimension_se','radius_worst', 'texture_worst','smoothness_worst', 'compactness_worst','concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst'], axis = 1, inplace = True)\n",
    "\n",
    "c_final = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy score is 92.46 percent\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score = cross_val_score(LogisticRegression(), W_final,c_final, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "print (\"The cross validated accuracy score is {:.2f} percent\").format(mean_cv_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is for the top 5 features from the statsmodels backward selection method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward selection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leveraged concave points worst and perimeter worst features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = df_train[df_train.columns.values]\n",
    "P.drop(['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se','area_se', 'smoothness_se', 'compactness_se', 'concavity_se','concave_points_se', 'symmetry_se', 'fractal_dimension_se','radius_worst', 'texture_worst','smoothness_worst', 'compactness_worst','concave_points_mean', 'symmetry_worst', 'fractal_dimension_worst','area_worst','concavity_mean','concavity_worst'], axis = 1, inplace = True)\n",
    "\n",
    "r = df_train.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model produces an accuracy score of 90.95 percent\n"
     ]
    }
   ],
   "source": [
    "#Intialize, fit, and score the model\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(P,r)\n",
    "\n",
    "score = lr.score(P,r)\n",
    "\n",
    "print (\"The model produces an accuracy score of {:.2f} percent\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "10-fold cross validation on training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy score is 90.93 percent\n"
     ]
    }
   ],
   "source": [
    "#Use cross_val_score method to generate the average accuracy score for 10 CVs\n",
    "mean_cv_score = cross_val_score(LogisticRegression(), P,r, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "print (\"The cross validated accuracy score is {:.2f} percent\").format(mean_cv_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation on entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P_final = df[df.columns.values]\n",
    "P_final.drop(['id','diagnosis','radius_mean','texture_mean','perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se','area_se', 'smoothness_se', 'compactness_se', 'concavity_se','concave_points_se', 'symmetry_se', 'fractal_dimension_se','radius_worst', 'texture_worst','smoothness_worst', 'compactness_worst','concave_points_mean', 'symmetry_worst', 'fractal_dimension_worst','area_worst','concavity_mean','concavity_worst'], axis = 1, inplace = True)\n",
    "\n",
    "r_final = df.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy score is 91.59 percent\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score = cross_val_score(LogisticRegression(), P_final,r_final, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "print (\"The cross validated accuracy score is {:.2f} percent\").format(mean_cv_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Then I re-ran the 10-fold cross validation on the training set, then entire dataset leveraging the entire feature set (30 features). X_final and y_final were defined for the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation on the training set - all 30 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy score is 94.68 percent\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score = cross_val_score(LogisticRegression(), X,y, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "print (\"The cross validated accuracy score is {:.2f} percent\").format(mean_cv_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold cross validation on the entire dataset - all 30 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy score is 95.09 percent\n"
     ]
    }
   ],
   "source": [
    "mean_cv_score = cross_val_score(LogisticRegression(), X_final,y_final, cv=10, scoring=\"accuracy\").mean()\n",
    "\n",
    "print (\"The cross validated accuracy score is {:.2f} percent\").format(mean_cv_score*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performed with the top 3 features from random forest (concave points worst, perimeter worst, and radius worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_knn_postrf = post random forest\n",
    "df_knn_postrf = df_train[['diagnosis','concave_points_worst', 'perimeter_worst', 'radius_worst']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_XX = ['concave_points_worst', 'perimeter_worst', 'radius_worst']\n",
    "XX = df_postrf[columns_XX]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(XX)\n",
    "\n",
    "XX = scaler.transform(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = df_knn_postrf.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 1).\\\n",
    "    fit(XX, cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(XX,cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc_hat = model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cc_hat == cc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True Class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hypotehsized Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True Class            0    1\n",
       "Hypotehsized Class          \n",
       "0                   249    0\n",
       "1                     0  149"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cc_hat,cc,rownames = ['Hypotehsized Class'], colnames=['True Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test sets (50/50) within the training subset of the overall dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_knn_postrf = df_knn_postrf.sample(frac = .5, random_state = 0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_knn_postrf = df_knn_postrf.drop(train_knn_postrf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix train_XX and response vector train_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_XX = train_knn_postrf[columns_XX]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(train_XX)\n",
    "train_XX = scaler.transform(train_XX)\n",
    "\n",
    "train_cc = train_knn_postrf.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix test_XX and response vector test_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_XX = test_knn_postrf[columns_XX]\n",
    "\n",
    "test_XX = scaler.transform(test_XX)\n",
    "\n",
    "test_cc = test_knn_postrf.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 fold CV on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 7...66, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cv = 10 # 10-fold CV\n",
    "k_nn = range(1, train_df.shape[0] * (k_cv - 1) / k_cv) # k-NN\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': k_nn, 'weights': ['uniform', 'distance']},\n",
    "    cv = model_selection.KFold(n_splits = k_cv, shuffle = True, random_state = 0)\n",
    ")\n",
    "\n",
    "gs.fit(train_XX, train_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94472361809045224"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 6, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94472361809045224"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(train_XX, train_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94974874371859297"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(test_XX, test_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95% accuracy on the test set within the overall training set, using 6 nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move to 10 fold cross validation on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 7...66, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[columns_XX]\n",
    "scaler = preprocessing.MinMaxScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "c = df.diagnosis\n",
    "#top part makes sense\n",
    "#redoing grid search\n",
    "k_cv = 10 # 10-fold CV\n",
    "k_nn = range(1, train_df.shape[0] * (k_cv - 1) / k_cv) # k-NN\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': k_nn, 'weights': ['uniform', 'distance']},\n",
    "    cv = model_selection.KFold(n_splits = k_cv, shuffle = True, random_state = 0)\n",
    ")\n",
    "\n",
    "gs.fit(X, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472759226713533"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 5, weights = 'uniform').\\\n",
    "    fit(train_XX, train_cc) # what should I be fitting to here?\n",
    "\n",
    "model.score(X, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN model leveraging the top 3 features from random forest has a 95% accuracy rate for the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Performed with the top 2 features from logistic regression forward selection (concave points worst, perimeter worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_knn_LR= KNN on logistic regression features\n",
    "df_knn_LR = df_train[['diagnosis','concave_points_worst', 'perimeter_worst']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_LR = ['concave_points_worst', 'perimeter_worst']\n",
    "LR = df_postrf[columns_LR]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(LR)\n",
    "\n",
    "LR = scaler.transform(LR)\n",
    "l = df_knn_postrf.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 1).\\\n",
    "    fit(LR, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(LR, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test sets (50/50) within the training subset of the overall dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_knn_LR = df_knn_LR.sample(frac = .5, random_state = 0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_knn_LR = df_knn_LR.drop(train_knn_LR.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix train_LR and response vector train_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_LR = train_knn_LR[columns_LR]\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(train_LR)\n",
    "train_LR = scaler.transform(train_LR)\n",
    "\n",
    "train_l = train_knn_LR.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix test_LR and response vector test_l:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_LR = test_knn_LR[columns_LR]\n",
    "\n",
    "test_LR = scaler.transform(test_LR)\n",
    "\n",
    "test_l = test_knn_LR.diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-fold CV on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 7...66, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_cv = 10 # 10-fold CV\n",
    "k_nn = range(1, train_df.shape[0] * (k_cv - 1) / k_cv) # k-NN\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': k_nn, 'weights': ['uniform', 'distance']},\n",
    "    cv = model_selection.KFold(n_splits = k_cv, shuffle = True, random_state = 0)\n",
    ")\n",
    "\n",
    "gs.fit(train_LR, train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92462311557788945"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 19, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=19, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9346733668341709"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(train_LR, train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95477386934673369"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(test_LR, test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will move to 10 fold cross validation on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=0, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 7...66, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], 'weights': ['uniform', 'distance']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = df[columns_LR]\n",
    "scaler = preprocessing.MinMaxScaler().fit(R)\n",
    "R = scaler.transform(R)\n",
    "\n",
    "q = df.diagnosis\n",
    "#top part makes sense\n",
    "#redoing grid search\n",
    "k_cv = 10 # 10-fold CV\n",
    "k_nn = range(1, train_df.shape[0] * (k_cv - 1) / k_cv) # k-NN\n",
    "\n",
    "gs = model_selection.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid = {'n_neighbors': k_nn, 'weights': ['uniform', 'distance']},\n",
    "    cv = model_selection.KFold(n_splits = k_cv, shuffle = True, random_state = 0)\n",
    ")\n",
    "\n",
    "gs.fit(R, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=14, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93848857644991213"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 19, weights = 'uniform').\\\n",
    "    fit(train_LR, train_l) \n",
    "\n",
    "model.score(R, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 94%, using 19 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
